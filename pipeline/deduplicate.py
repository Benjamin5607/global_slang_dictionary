import os
import pandas as pd
import csv
import re

SOURCE_FILES = [
    "output/raw_terms_urban.csv",
    "output/raw_terms_wiktionary.csv",
    "output/raw_terms_reddit.csv",
    "output/raw_terms_github_lists.csv"
]

os.makedirs("output", exist_ok=True)

dfs = []
for path in SOURCE_FILES:
    if os.path.exists(path) and os.path.getsize(path) > 0:
        try:
            # encoding="utf-8-sig" : ì—‘ì…€ì—ì„œ í•œê¸€ ì•ˆ ê¹¨ì§€ê²Œ í•˜ëŠ” ë§ˆë²•ì˜ ì¸ì½”ë”©
            df = pd.read_csv(path, on_bad_lines='skip', encoding="utf-8-sig")
            
            if df.shape[1] >= 5:
                df.columns = ["term", "definition", "source", "language", "country"]
                dfs.append(df)
        except Exception as e:
            print(f"âš ï¸ Error reading {path}: {e}")

if not dfs:
    print("âŒ No data found.")
    exit(0)

full_df = pd.concat(dfs, ignore_index=True)

# ğŸ› ï¸ [ìˆ˜ì •ë¨] ì •ê·œí™” ë¡œì§ ê°œì„ : ì˜ì–´ ì™¸ì˜ ë¬¸ì(í•œê¸€, í•œì ë“±)ë„ ì‚´ë¦¼!
# [^\w] : ë¬¸ìê°€ ì•„ë‹Œ ê²ƒ(ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ë“±)ë§Œ ì œê±°. í•œê¸€/í•œì/ì¼ë³¸ì–´ëŠ” \wì— í¬í•¨ë¨.
full_df["normalized"] = full_df["term"].astype(str).apply(lambda x: re.sub(r'[^\w]', '', x.lower()))

# ë¹ˆ ê°’ ì œê±° (ì •ê·œí™”í–ˆë”ë‹ˆ ì•„ë¬´ê²ƒë„ ì•ˆ ë‚¨ì€ ê²½ìš° ì‚­ì œ)
full_df = full_df[full_df["normalized"] != ""]

# ì¤‘ë³µ ì œê±°
full_df = full_df.drop_duplicates(subset=["normalized", "language"], keep='first')

# ì €ì¥ (utf-8-sig ì‚¬ìš©)
full_df.to_csv("output/raw_terms_clean.csv", index=False, encoding="utf-8-sig", quoting=csv.QUOTE_ALL)
print(f"ğŸ‰ Total merged terms: {len(full_df)} (Native Scripts Preserved!)")
